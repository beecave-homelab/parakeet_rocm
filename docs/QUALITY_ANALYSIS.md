# SRT Quality Analysis

Comprehensive guide to understanding and interpreting SRT subtitle quality metrics generated by the benchmark system.

## Overview

The quality analysis system evaluates SRT subtitle files against industry best practices for readability, accessibility, and technical compliance. It generates a composite quality score (0-1) along with detailed diagnostic metrics.

## Quality Score

### Score Range

- **0.0 - 0.6**: Poor quality, significant issues detected
- **0.6 - 0.8**: Moderate quality, some improvements needed
- **0.8 - 0.9**: Good quality, minor issues only
- **0.9 - 1.0**: Excellent quality, meets industry standards

### Scoring Algorithm

The system starts with a perfect score (1.0) and applies penalties based on violations:

```txt
Initial Score: 1.0

Penalties:
- Overlap violations:        -0.3 (any overlaps)
- Bad hyphen spacing:         -0.2 (if detected)
- Line length violations:     -0.0 to -0.3 (proportional)
- CPS non-compliance:         -0.0 to -0.2 (proportional)
- Duration violations:        -0.1 to -0.5 (baseline + proportional)

Final Score: max(0.0, score)
```

## Quality Metrics

### 1. Overlap Violations

**What it checks:** Segments where the start time occurs before the previous segment's end time.

**Why it matters:** Overlapping subtitles confuse viewers and can cause display issues on certain platforms.

**Ideal value:** 0 overlaps

**Example violation:**

```txt
Segment 1: 00:00:00,000 --> 00:00:02,000
Segment 2: 00:00:01,500 --> 00:00:03,000  ❌ Starts at 1.5s, overlaps with Segment 1
```

### 2. Hyphen Normalization

**What it checks:** Detects suspicious hyphen spacing patterns like "co -pilot" or "end - to-end".

**Why it matters:** Improper hyphen spacing indicates tokenization or text normalization issues that reduce readability.

**Ideal value:** `hyphen_normalization_ok: true`

**Common patterns flagged:**

- `"word -suffix"` → Should be `"word-suffix"`
- `"prefix- word"` → Should be `"prefix-word"`
- `"word - word"` → Should be `"word-word"` or separate words

### 3. Line Length Violations

**What it checks:** Lines exceeding 42 characters.

**Why it matters:** Long lines extend beyond typical screen widths and reduce readability on mobile devices and TVs.

**Industry standard:**

- **Maximum:** 42 characters per line
- **Recommended:** 35-40 characters for optimal readability

**Metrics provided:**

- `line_length_violations`: Count of lines exceeding limit
- `line_length_violation_ratio`: Proportion of violating lines
- `sample_offenders`: Up to 5 example violations with line content

### 4. Characters Per Second (CPS)

**What it checks:** Reading speed (characters/second) for each segment.

**Why it matters:** CPS directly affects readability. Too slow wastes screen time; too fast makes subtitles unreadable.

**Optimal range:** 10-22 CPS

- **Minimum:** 10 CPS (reading speed lower bound)
- **Maximum:** 22 CPS (reading speed upper bound)

**CPS Histogram:**

```json
{
  "below_min": 12,      // Segments < 10 CPS (too slow)
  "within_range": 143,  // Segments 10-22 CPS (optimal)
  "above_max": 8,       // Segments > 22 CPS (too fast)
  "total": 163
}
```

**Example CPS calculation:**

```txt
Text: "Hello world, this is a test."  (30 characters)
Duration: 2.5 seconds
CPS = 30 / 2.5 = 12 CPS  ✓ Within range
```

### 5. Duration Boundaries

**What it checks:** Segment duration constraints.

**Why it matters:** Very short segments flicker on screen; very long segments overwhelm viewers.

**Duration range:** 0.5 - 7.0 seconds

- **Minimum:** 0.5 seconds (prevents flickering)
- **Maximum:** 7.0 seconds (maintains attention)

**Boundary Counts:**

```json
{
  "within_range": 150,  // Segments with valid duration
  "too_short": 5,       // Segments < 0.5s
  "too_long": 8         // Segments > 7.0s
}
```

### 6. Duration Statistics

**Metrics provided:**

- `min_seconds`: Shortest segment duration
- `max_seconds`: Longest segment duration
- `average_seconds`: Mean segment duration
- `median_seconds`: Median segment duration

**Ideal distribution:**

- **Average:** 2-4 seconds
- **Median:** 2-3 seconds
- **No extremes:** Avoid segments < 0.5s or > 7.0s

## Sample Offenders

The analysis includes up to 5 sample violations for quick debugging:

### Line Length Offenders

```json
{
  "line_index": 42,
  "line": "This is an extremely long subtitle line that exceeds the limit",
  "length": 63,
  "limit": 42
}
```

### CPS Offenders

```json
{
  "segment_index": 15,
  "start": 10.5,
  "end": 11.0,
  "duration_seconds": 0.5,
  "cps": 28.0,
  "category": "above_max",
  "text": "Too fast!"
}
```

## Usage Examples

### Reading a Benchmark JSON

```python
import json

with open("benchmark_20250119_211200.json") as f:
    benchmark = json.load(f)

# Extract quality metrics
quality = benchmark["format_quality"]["srt"]
score = quality["score"]
details = quality["details"]

print(f"Quality Score: {score:.2f}")
print(f"Overlaps: {details['overlap_violations']}")
print(f"CPS Compliance: {details['cps_within_range_ratio']:.1%}")
```

### Interpreting Results

#### Example 1: High Quality Output (Score 0.95)

```json
{
  "score": 0.95,
  "details": {
    "overlap_violations": 0,
    "hyphen_normalization_ok": true,
    "line_length_violations": 2,
    "cps_within_range_ratio": 0.96,
    "boundary_counts": {
      "within_range": 148,
      "too_short": 1,
      "too_long": 1
    }
  }
}
```

**Interpretation:** Excellent quality with minor issues (2 long lines, 2 duration outliers).

#### Example 2: Moderate Quality (Score 0.72)

```json
{
  "score": 0.72,
  "details": {
    "overlap_violations": 0,
    "hyphen_normalization_ok": false,
    "line_length_violations": 15,
    "cps_within_range_ratio": 0.75,
    "boundary_counts": {
      "within_range": 120,
      "too_short": 15,
      "too_long": 10
    }
  }
}
```

**Interpretation:** Needs improvement. Issues include hyphen spacing, many long lines (15), and duration violations (25 segments).

## Best Practices

### Achieving High Quality Scores

1. **Enable Stabilization:** Use `--stabilize` flag to optimize timing and segmentation
2. **Use VAD:** Enable `--vad` to improve segment boundaries
3. **Tune Chunk Length:** Adjust `--chunk-len-sec` based on content type
4. **Review Thresholds:** Check CPS and duration histograms to identify patterns

### Addressing Common Issues

| Issue | Solution |
|-------|----------|
| Low CPS compliance | Adjust stabilization settings or use smaller chunk sizes |
| Many overlaps | Enable VAD or reduce batch overlap duration |
| Long lines | Enable word-level timestamps and regroup by character limits |
| Duration violations | Tune VAD threshold or adjust minimum segment duration |

## Technical Details

### Implementation

- **Module:** `parakeet_rocm/formatting/srt_quality.py`
- **Function:** `compute_srt_quality(segments, srt_text)`
- **Dependencies:** Standard library only (`statistics`)
- **Performance:** O(n) where n = number of segments

### Constants

Defined in `parakeet_rocm/utils/constant.py`:

```python
MIN_CPS = 10.0                      # Minimum characters per second
MAX_CPS = 22.0                      # Maximum characters per second
MAX_LINE_CHARS = 42                 # Maximum characters per line
MIN_SEGMENT_DURATION_SEC = 0.5     # Minimum segment duration
MAX_SEGMENT_DURATION_SEC = 7.0     # Maximum segment duration
```

## References

- **Netflix Timed Text Style Guide:** CPS and duration standards
- **BBC Subtitle Guidelines:** Line length and readability
- **W3C TTML Spec:** Accessibility and technical requirements
- **EBU-TT-D:** European Broadcasting Union technical standards

## See Also

- [Benchmark System Overview](../project-overview.md#benchmarking)
- [Configuration Guide](../README.md#configuration)
- [API Documentation](../project-overview.md#api)
