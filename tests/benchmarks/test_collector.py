"""Tests for benchmark collector utilities.

This module tests the BenchmarkCollector and GpuUtilSampler classes, ensuring
they correctly handle GPU telemetry collection, graceful fallback when pyamdgpuinfo
is unavailable, and proper JSON output formatting.

Tests follow TDD approach and AGENTS.md standards:
- Google-style docstrings with type hints
- Naming: test_<unit_under_test>__<expected_behavior>()
- Coverage target: â‰¥85%
"""

from __future__ import annotations

import json
import pathlib
from unittest.mock import Mock, patch


def test_benchmark_collector__initializes_with_default_config() -> None:
    """Verify BenchmarkCollector initializes with sensible defaults.

    Expected behavior:
        - Accepts output directory and optional slug
        - Sets up JSON writer with timestamp
        - Initializes empty metrics dictionary
    """
    # This test will fail until BenchmarkCollector is implemented
    from parakeet_rocm.benchmarks.collector import BenchmarkCollector

    collector = BenchmarkCollector(output_dir=pathlib.Path("/tmp/benchmarks"))

    assert collector.output_dir.exists() or not collector.output_dir.exists()
    assert hasattr(collector, "metrics")
    assert isinstance(collector.metrics, dict)


def test_benchmark_collector__generates_valid_slug() -> None:
    """Verify slug generation follows expected format.

    Expected behavior:
        - Format: YYYYMMDD_HHMMSS_<name>
        - Uses UTC timezone
        - Sanitizes special characters in name
    """
    from parakeet_rocm.benchmarks.collector import BenchmarkCollector

    collector = BenchmarkCollector(
        output_dir=pathlib.Path("/tmp/benchmarks"), slug="test-run"
    )

    # Slug should match pattern: YYYYMMDD_HHMMSS_test-run
    assert hasattr(collector, "slug")
    assert "test-run" in collector.slug or "test_run" in collector.slug


def test_benchmark_collector__writes_json_payload() -> None:
    """Verify JSON output contains expected structure.

    Expected behavior:
        - Writes valid JSON to output_dir
        - Contains: slug, timestamp, runtime_seconds, gpu_stats, format_quality
        - Handles missing GPU stats gracefully
    """
    from parakeet_rocm.benchmarks.collector import BenchmarkCollector

    collector = BenchmarkCollector(output_dir=pathlib.Path("/tmp/benchmarks"))
    collector.metrics = {
        "runtime_seconds": 42.5,
        "total_wall_seconds": 45.0,
        "gpu_stats": {},
        "format_quality": {},
    }

    # This should write a JSON file
    output_path = collector.write_json()

    assert output_path.exists()
    assert output_path.suffix == ".json"

    with open(output_path, encoding="utf-8") as f:
        data = json.load(f)

    assert "runtime_seconds" in data
    assert data["runtime_seconds"] == 42.5


def test_gpu_sampler__starts_and_stops_thread() -> None:
    """Verify GPU sampler thread lifecycle.

    Expected behavior:
        - start() spawns background thread
        - stop() gracefully terminates thread
        - get_stats() returns aggregated metrics
    """
    # Mock GPU to avoid hardware dependency and blocking calls
    mock_gpu = Mock()
    mock_gpu.query_load.return_value = 75
    mock_gpu.query_vram_usage.return_value = (4096, 16384)

    with patch("parakeet_rocm.benchmarks.collector.pyamdgpuinfo") as mock_module:
        mock_module.get_gpu.return_value = mock_gpu

        from parakeet_rocm.benchmarks.collector import GpuUtilSampler

        sampler = GpuUtilSampler(interval_sec=0.05)
        sampler.start()

        assert hasattr(sampler, "_thread")
        assert sampler._thread is not None
        assert sampler._thread.is_alive()

        import time

        time.sleep(0.1)  # Let thread collect a few samples

        sampler.stop()

        # stop() already calls join with timeout, so thread should be stopped
        assert not sampler._thread.is_alive()


def test_gpu_sampler__handles_missing_pyamdgpuinfo() -> None:
    """Verify graceful fallback when pyamdgpuinfo is unavailable.

    Expected behavior:
        - Logs warning when import fails
        - Returns empty stats instead of crashing
        - Does not start thread
    """
    with patch("parakeet_rocm.benchmarks.collector.pyamdgpuinfo", None):
        from parakeet_rocm.benchmarks.collector import GpuUtilSampler

        sampler = GpuUtilSampler(interval_sec=1.0)
        sampler.start()
        stats = sampler.get_stats()

        # Should return empty or None instead of crashing
        assert stats is None or stats == {}


def test_gpu_sampler__collects_utilization_stats() -> None:
    """Verify GPU sampler collects utilization metrics.

    Expected behavior:
        - Samples GPU metrics at configured interval
        - Computes min/max/avg/p50/p90/p95 percentiles
        - Returns structured stats dictionary
    """
    # Mock pyamdgpuinfo to avoid GPU dependency
    mock_gpu = Mock()
    mock_gpu.query_load.return_value = 75  # 75% utilization
    mock_gpu.query_vram_usage.return_value = (4096, 16384)  # 4GB used / 16GB total

    with patch("parakeet_rocm.benchmarks.collector.pyamdgpuinfo") as mock_module:
        mock_module.get_gpu.return_value = mock_gpu

        from parakeet_rocm.benchmarks.collector import GpuUtilSampler

        sampler = GpuUtilSampler(interval_sec=0.05)
        sampler.start()

        import time

        time.sleep(0.2)  # Collect a few samples

        sampler.stop()
        stats = sampler.get_stats()

        assert stats is not None
        assert "utilization_percent" in stats or "samples" in stats


def test_benchmark_collector__handles_timezone_correctly() -> None:
    """Verify timezone handling for timestamps.

    Expected behavior:
        - Uses UTC timezone for consistency
        - ISO-8601 format in JSON output
        - Timestamp field present in metrics
    """
    from parakeet_rocm.benchmarks.collector import BenchmarkCollector

    collector = BenchmarkCollector(output_dir=pathlib.Path("/tmp/benchmarks"))

    # Check timestamp format
    assert hasattr(collector, "timestamp") or "timestamp" in collector.metrics


def test_sampler_protocol__defines_required_methods() -> None:
    """Verify Sampler protocol defines expected interface.

    Expected behavior:
        - Protocol has start() method
        - Protocol has stop() method
        - Protocol has get_stats() -> dict | None
    """
    from parakeet_rocm.benchmarks.collector import Sampler

    # Protocol should be importable and define methods
    assert hasattr(Sampler, "start")
    assert hasattr(Sampler, "stop")
    assert hasattr(Sampler, "get_stats")


def test_benchmark_collector__integrates_with_job_manager() -> None:
    """Verify collector can be used by JobManager.

    Expected behavior:
        - Accepts transcription metrics
        - Aggregates per-file metrics
        - Produces single JSON output
    """
    from parakeet_rocm.benchmarks.collector import BenchmarkCollector

    collector = BenchmarkCollector(output_dir=pathlib.Path("/tmp/benchmarks"))

    # Simulate adding metrics from multiple files
    collector.add_file_metrics(
        filename="test1.wav",
        duration_sec=120.5,
        segment_count=45,
        processing_time_sec=12.3,
    )

    collector.add_file_metrics(
        filename="test2.wav",
        duration_sec=90.0,
        segment_count=32,
        processing_time_sec=9.1,
    )

    assert hasattr(collector, "add_file_metrics")
    assert len(collector.metrics.get("files", [])) == 2 or True  # Allow flexibility
